{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2b35ba",
   "metadata": {},
   "source": [
    "# **PRAKTIKUM 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, bobot: [0.19122914 0.51185289], bias: [-0.16050614]\n",
      "Epoch 2, bobot: [0.19122914 0.41185289], bias: [-0.26050614]\n",
      "Epoch 3, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 4, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 5, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 6, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 7, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 8, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 9, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n",
      "Epoch 10, bobot: [0.19122914 0.31185289], bias: [-0.36050614]\n"
     ]
    }
   ],
   "source": [
    "#Contoh code Perceptron sederhana\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Data input (X) dan target (y)\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])  # AND gate\n",
    "\n",
    "# Inisialisasi bobot dan bias\n",
    "w = np.random.rand(2)\n",
    "b = np.random.rand(1)\n",
    "lr = 0.1  # learning rate\n",
    "\n",
    "# Fungsi aktivasi (step function)\n",
    "def activation(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    for i in range(len(X)):\n",
    "        z = np.dot(X[i], w) + b\n",
    "        y_pred = activation(z)\n",
    "        error = y[i] - y_pred\n",
    "        # Update bobot\n",
    "        w += lr * error * X[i]\n",
    "        b += lr * error\n",
    "    print(f\"Epoch {epoch+1}, bobot: {w}, bias: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca7f77",
   "metadata": {},
   "source": [
    "# **TUGAS 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb11f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3236649623143848\n",
      "Epoch 1000, Loss: 0.2392112110301905\n",
      "Epoch 2000, Loss: 0.1548170622902639\n",
      "Epoch 3000, Loss: 0.04472828846488154\n",
      "Epoch 4000, Loss: 0.01635725420284842\n",
      "Epoch 5000, Loss: 0.00891683650218707\n",
      "Epoch 6000, Loss: 0.005899232454188924\n",
      "Epoch 7000, Loss: 0.004333163993501617\n",
      "Epoch 8000, Loss: 0.0033930925003662665\n",
      "Epoch 9000, Loss: 0.0027729590370575473\n",
      "Prediksi:\n",
      "[[0.02554025]\n",
      " [0.95510179]\n",
      " [0.94475267]\n",
      " [0.06021211]]\n"
     ]
    }
   ],
   "source": [
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9fef2",
   "metadata": {},
   "source": [
    "Hasil loss setelah perubahan hidden layer mengalami perubahan lebih cepat dengan sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b4dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.3274780407035275\n",
      "Epoch 1000, Loss: 0.012797082733424602\n",
      "Epoch 2000, Loss: 0.003283471866346602\n",
      "Epoch 3000, Loss: 0.001730956726043575\n",
      "Epoch 4000, Loss: 0.001146816158135167\n",
      "Epoch 5000, Loss: 0.0008463615651895275\n",
      "Epoch 6000, Loss: 0.0006661559173500909\n",
      "Epoch 7000, Loss: 0.0005467478016979456\n",
      "Epoch 8000, Loss: 0.00046239544032793036\n",
      "Epoch 9000, Loss: 0.0003996816119159116\n",
      "Prediksi:\n",
      "[[0.02970009]\n",
      " [0.98605912]\n",
      " [0.98605934]\n",
      " [0.01163533]]\n"
     ]
    }
   ],
   "source": [
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# Fungsi aktivasi output (tetap sigmoid)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85105b",
   "metadata": {},
   "source": [
    "Perbandingan loss sebelum menggunakna relU, loss berkurang lebih lamban hingga epoch. sedangkan setelah menggunakan relU, loss berkurang lebih cepat."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
